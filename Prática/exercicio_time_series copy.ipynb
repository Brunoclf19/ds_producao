{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64de1b9b",
   "metadata": {},
   "source": [
    "Continuar a partir de 7:40 (aula 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c00a7274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from statsmodels.tsa.ar_model import AutoReg as AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b6563ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2319a403",
   "metadata": {},
   "source": [
    "### Exercício \n",
    "\n",
    "A sua missão é prever 3 meses de uma série temporal de 2 anos, com início no dia 2020-01-01 e término no dia 2021-12-30, usando os mesmos parâmetros de quebra de premissas apresentadas nas aulas anteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b8c218",
   "metadata": {},
   "source": [
    "### Entregáveis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53a10d2",
   "metadata": {},
   "source": [
    "1. Código python para criar a série temporal do exercício"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aec066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações da serie\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "\n",
    "# criacao da series perfeita\n",
    "trend = np.linspace( 0, 0, n)\n",
    "noise = np.random.normal( 0, 1, n) \n",
    "serie_perfeita = trend + noise\n",
    "dates = pd.date_range( start='2020-01-01', end='2021-12-20', periods=n )\n",
    "serie_perfeita = pd.Series( serie_perfeita, index=dates, name='serie_perfeita')\n",
    "\n",
    "# Quebra Premissa 1: Linearidade \n",
    "trend_break = np.linspace( 0, 10, n )\n",
    "serie_nao_linear = serie_perfeita + trend_break\n",
    "\n",
    "# Quebra Premissa 2: Estacionariedade \n",
    "seasonality = 3 * np.sin( 2 * np.pi * np.arange( n ) / 50 )\n",
    "serie_nao_estacionaria = serie_perfeita + seasonality\n",
    "\n",
    "# Quebra Premissa 3: Autocorrelacao dos residucos \n",
    "autoregressive = np.zeros( n)\n",
    "autoregressive[0] = noise[0]\n",
    "for t in range( 1, n ):\n",
    " autoregressive[t] = 0.8 * autoregressive[t-1] + np.random.normal( 0, 0.5)\n",
    "serie_nao_autocorrelacao = serie_perfeita + autoregressive\n",
    "\n",
    "# Quebra Premissa 4: Homoscedasticidade \n",
    "non_normal = noise * np.linspace( 1, 3, n )\n",
    "serie_nao_homoscedastica = serie_perfeita + non_normal\n",
    "\n",
    "# Quebra Premissa 5: Não nomralidade dos residuos \n",
    "non_normal_noise = np.random.exponential( scale=1, size= n )\n",
    "serie_nao_normal = trend + non_normal_noise\n",
    "\n",
    "# Combinar as series\n",
    "serie_final = (\n",
    " serie_perfeita\n",
    " + trend_break\n",
    " + seasonality\n",
    " + autoregressive\n",
    " + non_normal\n",
    " + non_normal_noise\n",
    ")\n",
    "serie_final = pd.Series( serie_final, index=dates, name='serie_final' )\n",
    "serie_final = serie_final - serie_final.min() + 1\n",
    "\n",
    "# Visualizacao das series\n",
    "plt.figure( figsize=( 16, 8 ) )\n",
    "sns.lineplot( serie_final )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ab84a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. CRIAÇÃO DA SÉRIE COM QUEBRAS DE PREMISSAS ===\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "trend = np.linspace(0, 0, n)\n",
    "noise = np.random.normal(0, 1, n)\n",
    "serie_perfeita = trend + noise\n",
    "dates = pd.date_range(start='2020-01-01', end='2021-12-30', periods=n)\n",
    "serie_perfeita = pd.Series(serie_perfeita, index=dates, name='serie_perfeita')\n",
    "\n",
    "trend_break = np.linspace(0, 10, n)\n",
    "seasonality = 3 * np.sin(2 * np.pi * np.arange(n) / 50)\n",
    "autoregressive = np.zeros(n)\n",
    "autoregressive[0] = noise[0]\n",
    "for t in range(1, n):\n",
    "    autoregressive[t] = 0.8 * autoregressive[t - 1] + np.random.normal(0, 0.5)\n",
    "non_normal = noise * np.linspace(1, 3, n)\n",
    "non_normal_noise = np.random.exponential(scale=1, size=n)\n",
    "serie_final = (serie_perfeita + trend_break + seasonality + autoregressive + non_normal + non_normal_noise)\n",
    "serie_final = pd.Series(serie_final, index=dates, name='serie_final')\n",
    "serie_final = serie_final - serie_final.min() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcc9dc1",
   "metadata": {},
   "source": [
    "2. Código de separação dos conjuntos de treino, validação e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92285ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão da Série em Conjuntos de Treinamento, Validação e Teste\n",
    "train_size = int( 0.8 * len( serie_final ) )\n",
    "validation_size = int( 0.1 * len( serie_final ) )\n",
    "\n",
    "# Train-Val-Test Split\n",
    "train = serie_final[:train_size]\n",
    "validation = serie_final[train_size:train_size + validation_size]\n",
    "test = serie_final[train_size + validation_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44e9b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize=( 16, 8 ) )\n",
    "sns.lineplot( train, label='Train', color='blue' )\n",
    "sns.lineplot( validation, label='Validation', color='orange' )\n",
    "sns.lineplot( test, label='Test', color='green' )\n",
    "plt.title( 'Divisão da Série em Conjuntos de Treinamento, Validação e Teste' )\n",
    "plt.xlabel( 'Data' )\n",
    "plt.ylabel( 'Valores' )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9a6ff6",
   "metadata": {},
   "source": [
    "3. Código em python que realiza a previsão unicamente do próximo ponto da série de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f68baeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "train_series = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2109cbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão unicamente do próximo ponto da série de validação\n",
    "predictions = []\n",
    "actuals = []\n",
    "for i in range(len(validation)):\n",
    "    model = AR(train_series, lags=1)\n",
    "    model_fit = model.fit()\n",
    "    prediction = model_fit.forecast(steps=1).iloc[0]\n",
    "    predictions.append(prediction)  # Append the prediction to the list\n",
    "    actuals.append(validation.iloc[i])\n",
    "    train_series = pd.concat([train_series, pd.Series([validation.iloc[i]], index=[validation.index[i]])])\n",
    "\n",
    "# Avaliação do modelo\n",
    "df = pd.DataFrame({'Predictions': predictions, 'Actuals': actuals}, index=validation.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e293a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30e535d",
   "metadata": {},
   "source": [
    "4. Código em python para realizar a previsão de todos os pontos da série de validação usando a técnica de Rolling Forecast Origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae38182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão de todos os pontos da série de validação usando a tecnica de rolling forecast\n",
    "rolling_predictions = []\n",
    "train_series = train.copy()\n",
    "for i in range(len(validation)):\n",
    "    model = AR(train_series, lags=1)\n",
    "    model_fit = model.fit()\n",
    "    prediction = model_fit.forecast(steps=1).iloc[0]\n",
    "    rolling_predictions.append(prediction)  # Append the prediction to the list\n",
    "    train_series = pd.concat([train_series, pd.Series([prediction], index=[validation.index[i]])])\n",
    "\n",
    "# Avaliação do modelo\n",
    "df_rolling = pd.DataFrame({'Rolling Predictions': rolling_predictions, 'Actuals': actuals}, index=validation.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b964ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a5c57d",
   "metadata": {},
   "source": [
    "5. Código em python com a implementação das seguintes métricas de desempenho sobre os dados de validação: MAE, MAPE, RMSE, MSE, AIC e BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84bb972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementando metricas de desempenho nos dados de validação\n",
    "errors =  df['Actuals'] - df['Predictions']\n",
    "\n",
    "rmse = np.sqrt((errors**2).mean())\n",
    "mae = np.abs(errors).mean()\n",
    "mape = (np.abs(errors) / df['Actuals']).mean() * 100\n",
    "mse = (errors**2).mean()\n",
    "\n",
    "aic = 2 * (len(df) * np.log(np.std(errors)) + 1)\n",
    "bic = 2 * (len(df) * np.log(np.std(errors)) + 1 + 2 * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dc76fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors =  df['Actuals'] - df['Predictions']\n",
    "\n",
    "rmse = np.sqrt((errors**2).mean())\n",
    "mae = (np.abs(errors)).mean()\n",
    "mape = np.mean(np.abs(errors / df['Actuals']))\n",
    "log_likelihood = model_fit.llf\n",
    "num_params = model_fit.params.shape[0]\n",
    "num_obs = len(train_series)\n",
    "aic = -2 * log_likelihood + 2 * num_params\n",
    "bic = -2 * log_likelihood + num_params * np.log(num_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f35afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MAPE: {mape}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"AIC: {aic}\")\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd43a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MAPE: {mape}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"AIC: {aic}\")\n",
    "print(f\"BIC: {bic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa55a015",
   "metadata": {},
   "source": [
    "6. Código em python com a implementação do FINE-TUNING usando a técnica de Random Forest para valores lags entre 1 e 5. Use 3 iterações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937026c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning do ARIMA\n",
    "lags_values = [1, 2, 3, 4, 5]\n",
    "num_interations = 3\n",
    "results_val = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18f233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range (num_interations):\n",
    "    # Escolha de um valor aleatório para o lag\n",
    "    lag = np.random.choice(lags_values)\n",
    "    print(f\"Testando parâmetro: {lag}\")\n",
    "\n",
    "    # Start Rolling Forecast Origin\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    train_series = train.copy()\n",
    "    for t in range(len(validation)):\n",
    "        # Adicionando o valor real ao conjunto de treinamento\n",
    "        # train_series = train_series.append(validation.iloc[t])\n",
    "        \n",
    "        # Definindo o modelo\n",
    "        model = AR(train_series, lags=lag)\n",
    "        \n",
    "        # Treinamento do modelo\n",
    "        model_fit = model.fit()\n",
    "        \n",
    "        # Previsão para o próximo passo\n",
    "        forecast = model_fit.forecast(steps=1).iloc[0]\n",
    "        # Armazenando a previsão e o valor real\n",
    "        predictions.append(forecast)\n",
    "        actuals.append(validation.iloc[t])\n",
    "\n",
    "        # Adicionando o valor real ao conjunto de treinamento\n",
    "        train_series = pd.concat([train_series, pd.Series(validation.iloc[t], index=[validation.index[t]])])\n",
    "\n",
    "    # DataFrame para armazenar previsões e valores reais\n",
    "    df_val = pd.DataFrame({\n",
    "        'Previsão': predictions,\n",
    "        'Real': actuals\n",
    "    }, index=validation.index)\n",
    "\n",
    "    # Computando o desempenho\n",
    "    errors = df['Actuals'] - df['Predictions']\n",
    "    rmse_val = np.sqrt((errors**2).mean())\n",
    "    mae_val = (np.abs(errors)).mean()\n",
    "    mape_val = np.mean(np.abs(errors / df['Actuals']))\n",
    "\n",
    "    # Calculando AIC e BIC\n",
    "    log_likelihood = model_fit.llf\n",
    "    num_params = model_fit.params.shape[0]\n",
    "    num_obs = len(train_series)\n",
    "\n",
    "    aic_val = -2 * log_likelihood + 2 * num_params\n",
    "    bic_val = -2 * log_likelihood + num_params * np.log(num_obs)\n",
    "\n",
    "    performance = pd.DataFrame({'Lag': lag,\n",
    "                                'RMSE_VAL': rmse_val, \n",
    "                                'MAE_VAL': mae_val, \n",
    "                                'MAPE_VAL': mape_val, \n",
    "                                'AIC_VAL': aic_val, \n",
    "                                'BIC_VAL': bic_val}, index=[0]\n",
    "                                )\n",
    "    results_val = pd.concat([results_val, performance], ignore_index=True)\n",
    "\n",
    "# Exibindo os resultados\n",
    "results_val.sort_values(by='RMSE_VAL', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601926e6",
   "metadata": {},
   "source": [
    "7. Código em python que faça a união das séries de treinamento com a série de validação e faça o treinamento usando o melhor parâmetro definido no Fine-Turing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c79330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameter for fine-tuning\n",
    "lag = 5\n",
    "\n",
    "# Start Rolling Forecast Origin\n",
    "predictions = []\n",
    "actuals = []\n",
    "results_test = pd.DataFrame()\n",
    "train_series = pd.concat([train, validation])\n",
    "\n",
    "# Rolling Forecast Origin\n",
    "for t in range(len(test)):\n",
    "    # Adicionando o valor real ao conjunto de treinamento\n",
    "    # train_series = train_series.append(validation.iloc[t])\n",
    "\n",
    "    # Definindo o modelo\n",
    "    model = AR(train_series, lags=lag)\n",
    "\n",
    "    # Treinamento do modelo\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # Previsão para o próximo passo\n",
    "    forecast = model_fit.forecast(steps=1).iloc[0]\n",
    "    # Armazenando a previsão e o valor real\n",
    "    predictions.append(forecast)\n",
    "    actuals.append(test.iloc[t])\n",
    "\n",
    "    #Update the training set with the actual value\n",
    "    train_series = pd.concat([train_series, pd.Series(test.iloc[t], index=[test.index[t]])])\n",
    "# Adicionando o valor real ao conjunto de treinamento\n",
    "# train_series = train_series.append(validation.iloc[t])\n",
    "\n",
    "# DataFrame para armazenar previsões e valores reais\n",
    "df_test = pd.DataFrame({'Previsão': predictions,'Real': actuals}, index=test.index)\n",
    "\n",
    "# Computando o desempenho\n",
    "errors = df['Actuals'] - df['Predictions']\n",
    "\n",
    "rmse_test = np.sqrt((errors**2).mean())\n",
    "mae_test = (np.abs(errors)).mean()\n",
    "mape_test = np.mean(np.abs(errors / df['Actuals']))\n",
    "\n",
    "# Calculando AIC e BIC\n",
    "log_likelihood = model_fit.llf\n",
    "num_params = model_fit.params.shape[0]\n",
    "num_obs = len(train_series)\n",
    "\n",
    "aic_test = -2 * log_likelihood + 2 * num_params\n",
    "bic_test = -2 * log_likelihood + num_params * np.log(num_obs)\n",
    "\n",
    "results_test = pd.DataFrame({'Lag': lag,\n",
    "                             'RMSE_TEST': rmse_test,\n",
    "                             'MAE_TEST': mae_test,\n",
    "                             'MAPE_TEST': mape_test,\n",
    "                             'AIC_TEST': aic_test,\n",
    "                             'BIC_TEST': bic_test}, index=[0]\n",
    ")\n",
    "\n",
    "# Exibindo os resultados\n",
    "results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7135f91",
   "metadata": {},
   "source": [
    "8. Código em python da previsão sobre os dados de teste, bem como a tabela final com todas as métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d70d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fa1d5f4",
   "metadata": {},
   "source": [
    "9. Modularizar o código em python do item 8, criando funções para simplificar e modularizar o código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b165d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
